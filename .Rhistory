# # but for both the tweedie and the normal:
# df <-
#   expand.grid(
#     N = c(10, 100, 1000, 5000),
#     M = 1000,
#     type = c("tweedie", "normal"),
#     share_reject = NA
#   ) %>%
#   as_tibble()
#
#
# for (i in 1:nrow(df)) {
#   print(i)
#   df$share_reject[i] <-
#     MTests(df$N[i],
#            df$M[i],
#            df$type[i],
#            .05)
# }
#
# # As you see, with normally distributed data, N can
# # be very small and the t-test is fine. With a tweedie,
# # "large enough" can be many thousands. If we try
# # different distributions or parameterizations, we might
# # also get different results.
# df %>%
#   ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
#   geom_line() +
#   geom_hline(yintercept = .05) +
#   theme_bw()
#
# toc()
#
#time
library(tictoc)
library(doParallel)
library(foreach)
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
tic(paste0("Solution 29-35 ", num_cores, " cores"))
# Assignment 1:
library(tweedie)
library(ggplot2)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
df$share_reject <- foreach(i = 1:nrow(df), .combine = c, .packages = c("tweedie", "ggplot2")) %dopar% {
MTweedieTests(N = df$N[i], M = df$M[i], sig = .05)
}
stopCluster(cl)
## Assignemnt 4
# This is one way of solving it - maybe you have a better idea?
# First, write a function for simulating data, where the "type"
# argument controls the distribution. We also need to ensure
# that the mean "mu" is the same for both distributions. This
# argument will also be needed in the t-test for the null
# hypothesis. Therefore, if we hard code in a value here
# we may later have an inconsistency between the mean of the
# distributions and the t-test. So, we add it as an explicit
# argument:
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
library(tweedie)
library(ggplot2)
library(doParallel)
library(foreach)
num_cores <- detectCores()
registerDoParallel(cores=num_cores)
tic(paste0("Soltuion rewrite MTweedieTest ", num_cores, " cores"))
# Set up parallel backend
simTweedieTest <- function(N) {
t.test(rtweedie(N, mu=10000, phi=100, power=1.9), mu=10000)$p.value
}
MTweedieTests <- function(N,M,sig) {
p.values <- foreach(x = 1:M, .combine = c) %dopar% {
simTweedieTest(N)
}
sum(p.values < sig) / M
}
df <- expand.grid(N = c(10,100,1000,5000, 10000), M = 1000, share_reject = NA)
for(i in 1:nrow(df)) {
df$share_reject[i] <- MTweedieTests(N = df$N[i], M = df$M[i], sig = .05)
}
## Assignemnt 4
# This is one way of solving it - maybe you have a better idea?
# First, write a function for simulating data, where the "type"
# argument controls the distribution. We also need to ensure
# that the mean "mu" is the same for both distributions. This
# argument will also be needed in the t-test for the null
# hypothesis. Therefore, if we hard code in a value here
# we may later have an inconsistency between the mean of the
# distributions and the t-test. So, we add it as an explicit
# argument:
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
toc(log = TRUE)
printTicTocLog() %>%
knitr::kable()
source("scripts\/Task1.R")
source("scripts/Task1.R")
library(knitr)
library(doParallel)
library(tictoc)
# adding function to environment (used in 2 and 3 too)
printTicTocLog <-
function() {
tic.log() %>%
unlist %>%
tibble(logvals = .) %>%
separate(logvals,
sep = ":",
into = c("Function type", "log")) %>%
mutate(log = str_trim(log)) %>%
separate(log,
sep = " ",
into = c("Seconds"),
extra = "drop")
}
tic.clearlog() #clearling log for initial config
# taking time
cores <- min(1, detectCores())
tic("Regular loop")
# Assignment 1:
library(tweedie)
library(ggplot2)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N=df$N[i],
M=df$M[i],
sig=.05)
}
## Assignemnt 4
# This is one way of solving it - maybe you have a better idea?
# First, write a function for simulating data, where the "type"
# argument controls the distribution. We also need to ensure
# that the mean "mu" is the same for both distributions. This
# argument will also be needed in the t-test for the null
# hypothesis. Therefore, if we hard code in a value here
# we may later have an inconsistency between the mean of the
# distributions and the t-test. So, we add it as an explicit
# argument:
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
toc1 <- toc(log = TRUE)
?tibble
## Sourcing the different solutions and using tictoc to time them
library(tibble)
?tibble
?tibble
library(tweedie)
library(ggplot2)
library(doParallel)
library(foreach)
num_cores <- detectCores()
registerDoParallel(cores=num_cores)
tic(paste0("Soltuion rewrite MTweedieTest ", num_cores, " cores"))
# Set up parallel backend
simTweedieTest <- function(N) {
t.test(rtweedie(N, mu=10000, phi=100, power=1.9), mu=10000)$p.value
}
MTweedieTests <- function(N,M,sig) {
p.values <- foreach(x = 1:M, .combine = c) %dopar% {
simTweedieTest(N)
}
sum(p.values < sig) / M
}
df <- expand.grid(N = c(10,100,1000,5000, 10000), M = 1000, share_reject = NA)
for(i in 1:nrow(df)) {
df$share_reject[i] <- MTweedieTests(N = df$N[i], M = df$M[i], sig = .05)
}
## Assignemnt 4
# This is one way of solving it - maybe you have a better idea?
# First, write a function for simulating data, where the "type"
# argument controls the distribution. We also need to ensure
# that the mean "mu" is the same for both distributions. This
# argument will also be needed in the t-test for the null
# hypothesis. Therefore, if we hard code in a value here
# we may later have an inconsistency between the mean of the
# distributions and the t-test. So, we add it as an explicit
# argument:
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
toc(log = TRUE)
toc123 <- printTicTocLog() %>%
knitr::kable()
## Sourcing the different solutions and using tictoc to time them
library(tibble)
source("scripts/Task1.R")
source("scripts/Task2.R")
source("scripts/Task3.R")
toc123
## Sourcing the different solutions and using tictoc to time them
source("scripts/Task1.R")
source("scripts/Task2.R")
source("scripts/Task3.R")
toc123
# As we can see, the solution in task 3 is the fastest, with less than half of
# the time spent as the regular loop. This is not surprising, as we split the
# simulations in MTweedieTest in 8 cores. The first "solution" is simply the
# script itself, and in the second solution we see that we only use parallel
# computing in one the final loop, which means we run the M simulations on one
# core instead of several which is time consuming.
